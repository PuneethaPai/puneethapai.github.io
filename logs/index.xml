<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Logs on Puneeth</title><link>https://puneethapai.github.io/logs/</link><description>Recent content in Logs on Puneeth</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 27 Aug 2020 15:18:11 +0530</lastBuildDate><atom:link href="https://puneethapai.github.io/logs/index.xml" rel="self" type="application/rss+xml"/><item><title>Aug 27, 2020</title><link>https://puneethapai.github.io/logs/august-2020/27/</link><pubDate>Thu, 27 Aug 2020 15:18:11 +0530</pubDate><guid>https://puneethapai.github.io/logs/august-2020/27/</guid><description>FastAI Deep learning for coders: Course Link: https://course.fast.ai/videos/?lesson1=
Note: I had started with Machine Learning course from FastAI Link: https://course18.fast.ai/ml.html
Lesson 1:
Summary: Myths and actual truth around practical Deeplearning. Top down approach for practical DL over bottom up approach followed in academia. Base ball analogy for the same. Libraries covered Python -&amp;gt; Pytorch -&amp;gt; FastAI. Jupyter Notebooks: REPL (Read Execute Print Look). Similar to shell/terminal.</description></item><item><title>Aug 18, 2020</title><link>https://puneethapai.github.io/logs/august-2020/18/</link><pubDate>Tue, 18 Aug 2020 11:57:52 +0530</pubDate><guid>https://puneethapai.github.io/logs/august-2020/18/</guid><description>Hugo Larochell Neural Networks Back Propagation Algorithm: Validation of Back propagation of result using simple limit epsilon tends to zero
Regularization: Generally applied only to weights not baiases L2 Regularization: Takes square of weights Gaussian Prior, in probabilistic modelling says how the weights are generated L1 Regularization: Takes absolute values Laplacian Prior Makes some weights exactly=0 thus pruning connections Makes NNs less complex and to overfit data Generalization: Bias:</description></item><item><title>Aug 12, 2020</title><link>https://puneethapai.github.io/logs/august-2020/12/</link><pubDate>Tue, 11 Aug 2020 13:52:43 +0530</pubDate><guid>https://puneethapai.github.io/logs/august-2020/12/</guid><description>GAN for abstractive summarisation: Finished reading paper: Higlights are uploaded here Get To The Point - Summarization with Pointer-Generator Networks: Finished reading paper: Highlights are uploaded here Understood the pointer generator mechanism to be soft switch to select word token b/w source text attention and Pvoc. This gives the model edge as it can select OOV(Out of Vocabulary) word and also from vocabulary Coverage Mechanism: coverage vector ct, which is the sum of attention distributions over all previous decoder timesteps: covlosst =âˆ‘imin(ati,cti) General defination of Batch, Epoch, Iteration: Epoch: Number of time you go over the data set Batch: Consists of sample of you data for which you compute gradient and update weights: Training on single batch involve forward pass + Backward pass Forward Pass: Compute Loss Backward Pass: Compute Gradient and Update weights Iteration: Completion of 1 batch == 1 iteration Thus in 1 Epoch there will be |Trainin Data Size| / |Batch Sizee| number of iterations Example: If I have training data (100000 samples) and I consider batch_size = 100, then train for 50 Epochs means I will have</description></item><item><title>Aug 08, 2020</title><link>https://puneethapai.github.io/logs/august-2020/8/</link><pubDate>Sat, 08 Aug 2020 10:43:41 +0530</pubDate><guid>https://puneethapai.github.io/logs/august-2020/8/</guid><description>Exploring Abstractive vs Extractive Text summarization started with huggingface/transormers default pipeline model Really well trained but thought it was only extractive. We needed abstractive summary, also way to train model with data = (man page content, tldr summary) Found way to parse man pages for commands using groff $ groff -man -T utf8 $(man -w cp) $ tldr groff groff Typesetting program that reads plain text mixed with formatting commands and produces formatted output.</description></item><item><title>Aug 05, 2020</title><link>https://puneethapai.github.io/logs/august-2020/5/</link><pubDate>Wed, 05 Aug 2020 11:07:49 +0530</pubDate><guid>https://puneethapai.github.io/logs/august-2020/5/</guid><description>Stanford CS330: Multi-Task and Meta-Learning, 2019 | Lecture 2 - Multi-Task &amp;amp; Meta-Learning Basics
Notes:
while training a Classification NN, we will have learnt theta min for L(theta, f, D) is minimum we have final layer where P(y/x) is predicted If we compute P(a/y) at previous layers and reduce n/w computations How much back we can come in layers? Will it actually reduce computation and optimises state of the art NN?</description></item></channel></rss>