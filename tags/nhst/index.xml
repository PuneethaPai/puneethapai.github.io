<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NHST on Puneeth</title><link>https://puneethapai.github.io/tags/nhst/</link><description>Recent content in NHST on Puneeth</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 01 Sep 2020 11:44:52 +0530</lastBuildDate><atom:link href="https://puneethapai.github.io/tags/nhst/index.xml" rel="self" type="application/rss+xml"/><item><title>September 1 2020</title><link>https://puneethapai.github.io/logs/2020/september/1/</link><pubDate>Tue, 01 Sep 2020 11:44:52 +0530</pubDate><guid>https://puneethapai.github.io/logs/2020/september/1/</guid><description>Catostrophic forgetting: Fine tuned model for a specific task would be less good at the previous generic task on which it was pre-trained. This is called catastrophic forgetting. To retain the earlier learning you would want to revision by feeding few samples from previous task along with samples from our new specific task. Are p-values really that valuables? In hypothesis testing (I do get confused everytime) based on value of p we may either reject the null hypothesis (Ho) else we fail to reject Ho.</description></item></channel></rss>